{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"3\"\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For evaluating models\n",
    "\"\"\"\n",
    "# load the model accuracy results from the training data\n",
    "model_accuracy_table = pd.read_csv('data/model_accuracy_training_results.csv')\n",
    "\n",
    "# load the training and testing data\n",
    "\n",
    "training_data = pd.read_csv('data/train_data.csv')\n",
    "test_data = pd.read_csv('data/pre_test.csv')\n",
    "\"\"\"\n",
    "\n",
    "# For the final training data\n",
    "model_accuracy_table = pd.read_csv('data/model_accuracy_final_training_results.csv')\n",
    "\n",
    "training_data = pd.read_csv('data/final_training_data.csv')\n",
    "test_data = pd.read_csv('data/final_test_data.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the k nearest neighbors of a test sample\n",
    "\n",
    "def find_k_nearest_neighbors(test_sample, train_data, k):\n",
    "    # Initialize the Nearest Neighbors model\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    neigh.fit(train_data.drop(['PassengerId', 'Survived'], axis=1))\n",
    "\n",
    "    # Find the k nearest neighbors of the test sample\n",
    "    distances, indices = neigh.kneighbors([test_sample])\n",
    "\n",
    "    idx = train_data.iloc[indices[0]]['PassengerId'].values\n",
    "    \n",
    "\n",
    "    return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find nearest neighbors based on threshold distance\n",
    "\n",
    "def find_nearest_neighbors_by_distance(test_sample, train_data, dis):\n",
    "    # Initialize the Nearest Neighbors model\n",
    "    neigh = NearestNeighbors(metric = 'euclidean')\n",
    "    neigh.fit(train_data.drop(['PassengerId', 'Survived'], axis=1))\n",
    "\n",
    "    # Find a larger number of neighbors to ensure we capture enough points\n",
    "    distances, indices = neigh.kneighbors([test_sample], n_neighbors = 100)\n",
    "\n",
    "    # Filter neighbors based on the distancvce threshold\n",
    "    threshold_indices = indices[distances <= dis][0]['PassengerID'].values\n",
    "    print(type(threshold_indices))\n",
    "\n",
    "    return threshold_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_all_neighbors_in_cluster(test_sample, train_data, k = 22):\n",
    "    \"\"\"\n",
    "    This function aims to add the testing sample to the training data and run K-means clustering.\n",
    "    It then takes all of the training data that was clustered with the testing sample, \\\n",
    "    and outputs a numpy array of the indices of those training samples.\n",
    "\n",
    "    Parameters:\n",
    "    - test_sample: numpy array, the feature vector of the test sample\n",
    "    - train_data: numpy array, the feature vectors of the training samples\n",
    "    - n_clusters: int, the number of clusters to form\n",
    "    \n",
    "    Returns:\n",
    "    - passenger_ids: numpy array of the indices of the training samples in the same cluster as the test sample\n",
    "    \"\"\"\n",
    "\n",
    "    features = train_data.drop(['PassengerId', 'Survived'], axis=1, errors = 'ignore')\n",
    "    \n",
    "    if isinstance(test_sample, pd.Series):\n",
    "        test_sample = test_sample.values.reshape(1, -1)\n",
    "\n",
    "\n",
    "    # Add the test sample to the training features\n",
    "    combined_features = np.vstack([features, test_sample])\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters = k, random_state = 42).fit(combined_features)\n",
    "\n",
    "    # Find the cluster of the test sample (it's the last one because we appended it)\n",
    "    test_sample_cluster = kmeans.labels_[-1]\n",
    "    \n",
    "    # Find indices of training samples in the same cluster as the test sample\n",
    "    indices_in_cluster = np.where(kmeans.labels_[:-1] == test_sample_cluster)[0]\n",
    "    \n",
    "    # Retrieve PassengerId values for these indices\n",
    "    passenger_ids = train_data.iloc[indices_in_cluster]['PassengerId'].tolist()\n",
    "    \n",
    "    return passenger_ids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the weighted vote for a test sample\n",
    "\n",
    "def weighted_vote(test_sample, model_dict, train_data, model_accuracy, k=20):\n",
    "    \"\"\"\n",
    "    This funtion uses a basic voting strategy to classify a test sample.\n",
    "    First, it finds the k nearest neighbors of the test sample in the training data.\n",
    "    Then, it calculates the weighted vote for each model based on the accuracy of the model on the k nearest neighbors.\n",
    "    It allows every model to vote, but the vote is weighted based on the model's accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Find the IDs of the k nearest neighbors\n",
    "    nearest_ids = find_all_neighbors_in_cluster(test_sample, train_data, k=9)\n",
    "    \n",
    "\n",
    "    # Filter the model accuracy results for these IDs\n",
    "    nearest_performance = model_accuracy[model_accuracy['PassengerId'].isin(nearest_ids)]\n",
    "    \n",
    "    # Calculate the mean accuracy for each model for these nearest samples\n",
    "    mean_accuracies = nearest_performance.drop(['PassengerId'], axis=1).mean()\n",
    "    \n",
    "    # Initialize counters for weighted votes\n",
    "    weighted_votes_0 = 0\n",
    "    weighted_votes_1 = 0\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        # Get the binary prediction for the test sample\n",
    "        pred_class = model.predict([test_sample])[0]\n",
    "        # Apply the weight based on the model's accuracy to the vote\n",
    "        if pred_class == 0:\n",
    "            weighted_votes_0 += mean_accuracies[model_name]\n",
    "        else:\n",
    "            weighted_votes_1 += mean_accuracies[model_name]\n",
    "    \n",
    "    \n",
    "    # Determine the final classification based on the highest weighted vote\n",
    "    final_vote = 1 if weighted_votes_1 > weighted_votes_0 else 0   \n",
    "    \n",
    "    return final_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.8491620111731844\n"
     ]
    }
   ],
   "source": [
    "test_model(select_top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_model(test_sample, model_dict, train_data, model_accuracy):\n",
    "    \"\"\"\n",
    "    This function uses a basic selection strategy to classify a test sample.\n",
    "    First, it finds the k nearest neighbors of the test sample in the training data.\n",
    "    Then, it selects the top model based on the accuracy of the model on the k nearest neighbors.\n",
    "    It has that model classify the training sample, and returns the result.\n",
    "\n",
    "    NOTE this is considered a Dynamic Classifier Selection (DCS) strategy rather than an ensemble method.\n",
    "    \"\"\"\n",
    "\n",
    "    #logging.debug(f\"Processing test data passenger ID: {passenger_id}\")\n",
    "    \n",
    "    # Find the IDs of the k nearest neighbors\n",
    "    nearest_ids = find_k_nearest_neighbors(test_sample, train_data, k = 30)\n",
    "    #nearest_ids = find_all_neighbors_in_cluster(test_sample, train_data)\n",
    "\n",
    "    \n",
    "    #logging.debug(f\"K nearest neighbors: {nearest_ids}\")\n",
    "    \n",
    "    # Filter the model accuracy results for these IDs\n",
    "    nearest_performance = model_accuracy[model_accuracy['PassengerId'].isin(nearest_ids)]\n",
    "    \n",
    "    # Calculate the mean accuracy for each model for these nearest samples\n",
    "    mean_accuracies = nearest_performance.drop(['PassengerId'], axis=1).mean()\n",
    "    #logging.debug(f\"Average score of each model on those K nearest neighbors: {mean_accuracies.to_dict()}\")\n",
    "    \n",
    "    # Select the top model based on the mean accuracy\n",
    "    top_model = mean_accuracies.idxmax()\n",
    "\n",
    "    # Get the binary prediction for the test sample\n",
    "    pred_class = model_dict[top_model].predict([test_sample])[0]\n",
    "    return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_weighted_vote(test_sample, model_dict, train_data, model_accuracy, k=20, thresh = 0.9):\n",
    "    \"\"\" \n",
    "    This function acts as a sliding middle ground between the two above selection methods.\n",
    "    It first selects the top model based on the accuracy of the model on the k nearest neighbors.\n",
    "    Then, it chooses models that are with a certain threshold of the top model's accuracy.\n",
    "    It only allows models that are within this threshold to vote, and the vote is weighted based on the model's accuracy.\n",
    "\n",
    "    If the thresh is set to zero, this function will act exactly the same as the weighted_vote function.\n",
    "    If the thresh is set to one, this function will act very similarly to the select_top_model function (the difference being that if there are ties for the top model, then both will be selected to vote, \n",
    "        rather than .idmax() picking the first model in the list.)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # Find the IDs of the k nearest neighbors\n",
    "    nearest_ids = find_k_nearest_neighbors(test_sample, train_data, k)\n",
    "\n",
    "    # Filter the model accuracy results for these IDs\n",
    "    nearest_performance = model_accuracy[model_accuracy['PassengerId'].isin(nearest_ids)]\n",
    "\n",
    "    # Calculate the mean accuracy for each model for these nearest samples\n",
    "    mean_accuracies = nearest_performance.drop(['PassengerId'], axis=1).mean()\n",
    "\n",
    "    # Select the top model based on the mean accuracy\n",
    "    best_model_accuracy = mean_accuracies.max()\n",
    "\n",
    "    # If the best model's accuracy is above a certain threshold, use that model\n",
    "    \n",
    "    eligible_models = mean_accuracies[mean_accuracies >= thresh * best_model_accuracy]\n",
    "\n",
    "    # Initialize weighted vote counters\n",
    "    weighted_votes = {0: 0, 1: 0}\n",
    "\n",
    "    for model_name in eligible_models.index:\n",
    "        model = model_dict[model_name]\n",
    "        pred_class = model.predict([test_sample])[0]\n",
    "\n",
    "        # Weight the vote by the model's mean accuracy\n",
    "        weighted_votes[pred_class] += mean_accuracies[model_name]\n",
    "\n",
    "    # Determine the final classification based on the highest weighted vote\n",
    "    final_vote = 1 if weighted_votes[1] > weighted_votes[0] else 0\n",
    "\n",
    "    return final_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import os\n",
    "\n",
    "\n",
    "def load_models():\n",
    "    # define the model directory\n",
    "    models_dir = 'models'\n",
    "\n",
    "    model_files = {\n",
    "        'ProportionCorrectLogisticRegression': 'logistic_regression_model.pkl',\n",
    "        'ProportionCorrectRandomForest': 'random_forest_model.pkl',\n",
    "        'ProportionCorrectXGBoost': 'xgboost_model.pkl',\n",
    "        'ProportionCorrectLightBoost': 'lightboost_model.pkl',\n",
    "        'ProportionCorrectCatBoost': 'catboost_model.pkl'\n",
    "    }\n",
    "\n",
    "    models = {}\n",
    "\n",
    "    for model_name, model_file in model_files.items():\n",
    "        file_path = os.path.join(models_dir, model_file)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            models[model_name] = load(file)\n",
    "\n",
    "    return models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_data.drop(['PassengerId', 'Survived'], axis=1), test_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Model Accuracy:  0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the predictions\n",
    "ensemble_predictions = []\n",
    "\n",
    "# Load the models\n",
    "models = load_models()\n",
    "\n",
    "# Iterate over the test data\n",
    "for index, row in X_test.iterrows():\n",
    "    test_sample = row.values\n",
    "\n",
    "    predicted_label = selective_weighted_vote(test_sample, models, training_data, model_accuracy_table)\n",
    "    ensemble_predictions.append(predicted_label)\n",
    "\n",
    "# Calculate the accuracy of the ensemble model\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "\n",
    "print('Model Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(voting_strategy):\n",
    "    # Initialize the predictions\n",
    "    ensemble_predictions = []\n",
    "\n",
    "    # Load the models\n",
    "    models = load_models()\n",
    "\n",
    "    # Iterate over the test data\n",
    "    for index, row in X_test.iterrows():\n",
    "        test_sample = row.values\n",
    "\n",
    "        predicted_label = voting_strategy(test_sample, models, training_data, model_accuracy_table)\n",
    "        ensemble_predictions.append(predicted_label)\n",
    "\n",
    "    # Calculate the accuracy of the ensemble model\n",
    "    accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "\n",
    "    print('Model Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# To ignore specific UserWarnings about feature names\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(weighted_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "test_model(selective_weighted_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy:  0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "# use each model on its own to predict the test data as a benchmark\n",
    "# Logistic Regression\n",
    "\n",
    "logistic_regression_model = models['ProportionCorrectLogisticRegression']\n",
    "logistic_regression_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "logistic_regression_accuracy = accuracy_score(y_test, logistic_regression_predictions)\n",
    "\n",
    "print('Logistic Regression Model Accuracy: ', logistic_regression_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy:  0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest_model = models['ProportionCorrectRandomForest']\n",
    "random_forest_predictions = random_forest_model.predict(X_test)\n",
    "\n",
    "random_forest_accuracy = accuracy_score(y_test, random_forest_predictions)\n",
    "\n",
    "print('Random Forest Model Accuracy: ', random_forest_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy:  0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "xgboost_model = models['ProportionCorrectXGBoost']\n",
    "xgboost_predictions = xgboost_model.predict(X_test)\n",
    "\n",
    "xgboost_accuracy = accuracy_score(y_test, xgboost_predictions)\n",
    "\n",
    "print('XGBoost Model Accuracy: ', xgboost_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightBoost Model Accuracy:  0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "# LightBoost\n",
    "\n",
    "lightboost_model = models['ProportionCorrectLightBoost']\n",
    "lightboost_predictions = lightboost_model.predict(X_test)\n",
    "\n",
    "lightboost_accuracy = accuracy_score(y_test, lightboost_predictions)\n",
    "\n",
    "print('LightBoost Model Accuracy: ', lightboost_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Model Accuracy:  0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "\n",
    "catboost_model = models['ProportionCorrectCatBoost']\n",
    "catboost_predictions = catboost_model.predict(X_test)\n",
    "\n",
    "catboost_accuracy = accuracy_score(y_test, catboost_predictions)\n",
    "\n",
    "print('CatBoost Model Accuracy: ', catboost_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "[[892, 0], [893, 0], [894, 0], [895, 0], [896, 1], [897, 0], [898, 1], [899, 0], [900, 1], [901, 0], [902, 0], [903, 0], [904, 1], [905, 0], [906, 1], [907, 1], [908, 0], [909, 0]]\n"
     ]
    }
   ],
   "source": [
    "# Final procedure to predict test data\n",
    "\n",
    "\"\"\"\n",
    "Loop through each element in test data\n",
    "run KNN to find the training samples most closely related to the testing sample\n",
    "find the top model for the related training data\n",
    "use the top model to predict the status of the testing sample\n",
    "append the passengerID and the prediction to a list\n",
    "\n",
    "save the list to a csv file\n",
    "\"\"\"\n",
    "\n",
    "testing_predictions = []\n",
    "\n",
    "models = load_models()\n",
    "\n",
    "X_test, passenger_id = test_data.drop(['PassengerId'], axis=1), test_data['PassengerId']\n",
    "\n",
    "for index, row in X_test.iterrows():\n",
    "    test_sample = row.values\n",
    "\n",
    "    predicted_label = select_top_model(test_sample, models, training_data, model_accuracy_table)\n",
    "    testing_predictions.append([passenger_id[index], predicted_label])\n",
    "\n",
    "\n",
    "# print the length of the predictions\n",
    "print(len(testing_predictions))\n",
    "\n",
    "# print the first 10 rows of testing_predictions\n",
    "print(testing_predictions[:18])\n",
    "\n",
    "# convert testing_predicitons to a dataframe and add the header row 'PassengerId, Survived'\n",
    "testing_predictions = pd.DataFrame(testing_predictions, columns=['PassengerId', 'Survived'])\n",
    "testing_predictions.to_csv('data/final_predictions.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kuzco_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
